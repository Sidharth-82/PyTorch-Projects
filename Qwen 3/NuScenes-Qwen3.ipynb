{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bb544b2f-b6f5-4e48-b562-242fef324d4e",
    "_uuid": "f05bce84-62ba-44f3-8676-14e7f407f3a1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-02-13T18:20:07.883680Z",
     "iopub.status.busy": "2026-02-13T18:20:07.882828Z",
     "iopub.status.idle": "2026-02-13T18:20:08.161588Z",
     "shell.execute_reply": "2026-02-13T18:20:08.160821Z",
     "shell.execute_reply.started": "2026-02-13T18:20:07.883650Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "22433e51-538c-402a-9279-2fcdc9eb5de1",
    "_uuid": "74dd658a-07bc-4de0-8c8a-1048dc8b06a1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-02-13T18:20:08.163149Z",
     "iopub.status.busy": "2026-02-13T18:20:08.162795Z",
     "iopub.status.idle": "2026-02-13T18:20:16.220341Z",
     "shell.execute_reply": "2026-02-13T18:20:16.219608Z",
     "shell.execute_reply.started": "2026-02-13T18:20:08.163126Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip3 install bitsandbytes peft trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dd00da00-6f39-42ae-ba4c-d65b6be362bc",
    "_uuid": "8b17430f-17c3-488d-a24d-b3421af3431f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-02-13T18:24:08.703411Z",
     "iopub.status.busy": "2026-02-13T18:24:08.702562Z",
     "iopub.status.idle": "2026-02-13T18:24:08.707985Z",
     "shell.execute_reply": "2026-02-13T18:24:08.707411Z",
     "shell.execute_reply.started": "2026-02-13T18:24:08.703377Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "from transformers import Qwen3VLForConditionalGeneration, Qwen3VLProcessor, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "71bba297-9729-4ee8-835f-37b280c6b0e7",
    "_uuid": "cd67631f-d0b8-43f3-a4f0-51bab51d8c8e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-02-13T18:53:48.126350Z",
     "iopub.status.busy": "2026-02-13T18:53:48.126070Z",
     "iopub.status.idle": "2026-02-13T18:53:48.131994Z",
     "shell.execute_reply": "2026-02-13T18:53:48.131334Z",
     "shell.execute_reply.started": "2026-02-13T18:53:48.126327Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "MODEL_ID = \"Qwen/Qwen3-VL-8B-Instruct\"\n",
    "EPOCHS = 1\n",
    "\n",
    "BATCH_SIZE = 1 #low due to lack of hardware to support\n",
    "GRADIENT_CHECKPOINTING = True #improves memory efficiency, but increases computation time\n",
    "USE_REENTRANT = False\n",
    "OPTIM = \"paged_adamw_32bit\"\n",
    "LEARNING_RATE = 2e-5\n",
    "LOGGING_STEPS = 50\n",
    "EVAL_STEPS = 50\n",
    "SAVE_STEPS = 50\n",
    "EVAL_STRATEGY = \"steps\"\n",
    "SAVE_STRATEGY = \"steps\"\n",
    "METRIC_FOR_BEST_MODEL = \"eval_loss\"\n",
    "LOAD_BEST_MODEL_AT_END = True\n",
    "MAX_GRAD_NORM = 1\n",
    "WARMUP_STEPS = 0\n",
    "DATASET_KWARGS = {\"skip_prepare_datset\" : True} #no need to prepare data as it will be done already\n",
    "REMOVE_UNUSED_COLUMNS = False #Necessary for VLMS\n",
    "MAX_SEQ_LEN = 128\n",
    "DATASET_LENGTH = 283\n",
    "NUM_STEPS = (DATASET_LENGTH // BATCH_SIZE) * EPOCHS\n",
    "print(NUM_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:42:08.571970Z",
     "iopub.status.busy": "2026-02-13T18:42:08.571450Z",
     "iopub.status.idle": "2026-02-13T18:42:08.578978Z",
     "shell.execute_reply": "2026-02-13T18:42:08.578427Z",
     "shell.execute_reply.started": "2026-02-13T18:42:08.571940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a multimodal driving-scene reasoning assistant for autonomous driving systems.\n",
    "\n",
    "You are provided with:\n",
    "- Multiple synchronized camera images from different viewpoints (e.g., front, rear, left, right).\n",
    "- LiDAR data describing the 3D structure of the scene.\n",
    "- A natural-language question about the driving environment.\n",
    "\n",
    "Your task is to answer the question by jointly reasoning over ALL available modalities.\n",
    "\n",
    "You must:\n",
    "- Fuse information across all camera views and the LiDAR data to form a coherent understanding of the scene.\n",
    "- Use camera images to identify visual attributes such as objects, signs, signals, weather, lighting, and semantics.\n",
    "- Use LiDAR data to reason about 3D structure, distance, relative position, size, motion cues, and occlusions.\n",
    "- Cross-check information between modalities when possible.\n",
    "- Prioritize safety-aware and conservative reasoning when uncertainty exists.\n",
    "\n",
    "You must NOT:\n",
    "- Assume viewpoints, objects, or measurements not supported by the inputs.\n",
    "- Hallucinate depth, distance, or object presence without LiDAR or clear visual evidence.\n",
    "- Ignore any modality unless it is missing or explicitly empty.\n",
    "\n",
    "Answering rules:\n",
    "- Answer concisely and directly.\n",
    "- Ground every conclusion in observable evidence from the inputs.\n",
    "- Do not mention internal reasoning, model details, or the prompt itself.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def format_data(sample):\n",
    "    \"\"\"\n",
    "    Formats a NuScenes QA sample with multi-camera images and LiDAR data\n",
    "    for Qwen3-8B-Instruct multimodal training or inference.\n",
    "\n",
    "    Args:\n",
    "        sample (dict): One dataset row with required headers\n",
    "\n",
    "    Returns:\n",
    "        dict: Chat-formatted multimodal example\n",
    "    \"\"\"\n",
    "\n",
    "    user_content = []\n",
    "\n",
    "    # --- Camera views (ordered, explicit) ---\n",
    "    camera_keys = [\n",
    "        \"CAM_FRONT\",\n",
    "        \"CAM_FRONT_RIGHT\",\n",
    "        \"CAM_BACK_RIGHT\",\n",
    "        \"CAM_BACK\",\n",
    "        \"CAM_BACK_LEFT\",\n",
    "        \"CAM_FRONT_LEFT\",\n",
    "    ]\n",
    "\n",
    "    for cam in camera_keys:\n",
    "        if cam in sample and sample[cam] is not None:\n",
    "            user_content.append({\n",
    "                \"type\": \"image\",\n",
    "                \"image\": Image.fromarray(np.array(sample[cam]), 'RGB'),\n",
    "                \"view\": cam\n",
    "            })\n",
    "\n",
    "    # --- LiDAR input ---\n",
    "    if \"LIDAR_TOP\" in sample and sample[\"LIDAR_TOP\"] is not None:\n",
    "        user_content.append({\n",
    "            \"type\": \"lidar\",\n",
    "            \"lidar\": sample[\"LIDAR_TOP\"],\n",
    "            \"view\": \"LIDAR_TOP\"\n",
    "        })\n",
    "\n",
    "    # --- Question ---\n",
    "    user_content.append({\n",
    "        \"type\": \"text\",\n",
    "        \"text\": sample[\"question\"]\n",
    "    })\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_content\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # --- Assistant answer (training only) ---\n",
    "    if \"answer\" in sample and sample[\"answer\"] is not None:\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": sample[\"answer\"]\n",
    "        })\n",
    "\n",
    "    return {\"messages\": messages}\n",
    "    # return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:21:00.046005Z",
     "iopub.status.busy": "2026-02-13T18:21:00.045761Z",
     "iopub.status.idle": "2026-02-13T18:21:20.032150Z",
     "shell.execute_reply": "2026-02-13T18:21:20.031570Z",
     "shell.execute_reply.started": "2026-02-13T18:21:00.045975Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_stream = load_dataset(\n",
    "    \"KevinNotSmile/nuscenes-qa-mini\",\n",
    "    \"night\",\n",
    "    split=\"train\",\n",
    "    streaming=True,\n",
    ")\n",
    "train_dataset = Dataset.from_generator(lambda: train_stream.take(3))\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:21:20.033336Z",
     "iopub.status.busy": "2026-02-13T18:21:20.033088Z",
     "iopub.status.idle": "2026-02-13T18:21:35.191272Z",
     "shell.execute_reply": "2026-02-13T18:21:35.190678Z",
     "shell.execute_reply.started": "2026-02-13T18:21:20.033316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_stream = load_dataset(\n",
    "    \"KevinNotSmile/nuscenes-qa-mini\",\n",
    "    \"night\",\n",
    "    split=\"validation\",\n",
    "    streaming=True,\n",
    ")\n",
    "eval_dataset = Dataset.from_generator(lambda: eval_stream.take(1))\n",
    "print(len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:24:18.544724Z",
     "iopub.status.busy": "2026-02-13T18:24:18.544034Z",
     "iopub.status.idle": "2026-02-13T18:24:18.548637Z",
     "shell.execute_reply": "2026-02-13T18:24:18.547967Z",
     "shell.execute_reply.started": "2026-02-13T18:24:18.544675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(train_dataset)\n",
    "print('-'*30)\n",
    "print(eval_dataset)\n",
    "print('-'*30)\n",
    "# print(train_dataset[0])\n",
    "# print('-'*30)\n",
    "# print(eval_dataset[0])\n",
    "# print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:42:13.879128Z",
     "iopub.status.busy": "2026-02-13T18:42:13.878396Z",
     "iopub.status.idle": "2026-02-13T18:42:18.445950Z",
     "shell.execute_reply": "2026-02-13T18:42:18.445177Z",
     "shell.execute_reply.started": "2026-02-13T18:42:13.879100Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "train_dataset_formated = [format_data(sample) for sample in train_dataset]\n",
    "eval_dataset_formated = [format_data(sample) for sample in eval_dataset]\n",
    "test_dataset_formated = train_dataset_formated[math.ceil(len(train_dataset_formated) * 0.66):]\n",
    "train_dataset_formated = train_dataset_formated[:math.ceil(len(train_dataset_formated) * 0.66)]\n",
    "print(len(train_dataset_formated))\n",
    "print(len(eval_dataset_formated))\n",
    "print(len(test_dataset_formated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-13T18:21:36.237589Z",
     "iopub.status.idle": "2026-02-13T18:21:36.237870Z",
     "shell.execute_reply": "2026-02-13T18:21:36.237760Z",
     "shell.execute_reply.started": "2026-02-13T18:21:36.237743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(train_dataset_formated[0]['messages'][1]['content'][5]['view']) #should print \"CAM_FRONT_LEFT\"\n",
    "print(eval_dataset_formated[0]['messages'][1]['content'][5]['view']) #print CAM_FRONT_LEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:25:12.950991Z",
     "iopub.status.busy": "2026-02-13T18:25:12.950447Z",
     "iopub.status.idle": "2026-02-13T18:28:29.462375Z",
     "shell.execute_reply": "2026-02-13T18:28:29.461758Z",
     "shell.execute_reply.started": "2026-02-13T18:25:12.950967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit = True,\n",
    "        bnb_4bit_use_double_quant = True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "    model  = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        device_map = \"auto\",\n",
    "        quantization_config = bnb_config\n",
    "    )\n",
    "\n",
    "else:\n",
    "    model  = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "        MODEL_ID\n",
    "    )\n",
    "\n",
    "processor = Qwen3VLProcessor.from_pretrained(MODEL_ID)\n",
    "processor.tokenizer.padding_side = \"right\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:42:41.794163Z",
     "iopub.status.busy": "2026-02-13T18:42:41.793587Z",
     "iopub.status.idle": "2026-02-13T18:42:41.797587Z",
     "shell.execute_reply": "2026-02-13T18:42:41.797028Z",
     "shell.execute_reply.started": "2026-02-13T18:42:41.794139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_data = test_dataset_formated[0]\n",
    "# sample_question = sample_data[\"messages\"][1][\"content\"][7][\"text\"]\n",
    "# sample_answer = sample_data[\"messages\"][2][\"content\"]\n",
    "# sample_image = sample_data[\"messages\"][1][\"content\"][:5]\n",
    "# sample_lidar = sample_data[\"messages\"][1][\"content\"][:5]\n",
    "\n",
    "# print(sample_question)\n",
    "# print(sample_answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:42:43.448794Z",
     "iopub.status.busy": "2026-02-13T18:42:43.448096Z",
     "iopub.status.idle": "2026-02-13T18:42:55.796410Z",
     "shell.execute_reply": "2026-02-13T18:42:55.795766Z",
     "shell.execute_reply.started": "2026-02-13T18:42:43.448769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def text_generator(sample_data, add_generation_prompt=True):\n",
    "    \"\"\"\n",
    "    Converts a formatted multimodal chat sample into model-ready text\n",
    "    using the processor's chat template.\n",
    "\n",
    "    Args:\n",
    "        sample_data (dict): Must contain \"messages\"\n",
    "        processor: Qwen processor/tokenizer\n",
    "        add_generation_prompt (bool): \n",
    "            - False for training\n",
    "            - True for inference\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted text prompt\n",
    "    \"\"\"\n",
    "\n",
    "    text = processor.apply_chat_template(\n",
    "        sample_data[\"messages\"][0:2],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=add_generation_prompt\n",
    "    )\n",
    "\n",
    "    # print(f\"prompt: {text}\")\n",
    "\n",
    "    image_inputs = [views['image'] for views in sample_data[\"messages\"][1][\"content\"][:6]]\n",
    "\n",
    "    inputs = processor(\n",
    "        text = [text],\n",
    "        images = [image_inputs],\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens = MAX_SEQ_LEN)\n",
    "\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids, skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    del inputs\n",
    "\n",
    "    actual_answer = sample_data[\"messages\"][2][\"content\"]\n",
    "    \n",
    "\n",
    "    return output_text[0], actual_answer\n",
    "\n",
    "generated_text, actual_answer = text_generator(sample_data)\n",
    "print(f\"Generated Answer: {generated_text}\")\n",
    "print(f\"Actual Answer: {actual_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-13T18:21:36.244168Z",
     "iopub.status.idle": "2026-02-13T18:21:36.244530Z",
     "shell.execute_reply": "2026-02-13T18:21:36.244379Z",
     "shell.execute_reply.started": "2026-02-13T18:21:36.244361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(train_dataset_formated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:52:59.158558Z",
     "iopub.status.busy": "2026-02-13T18:52:59.158051Z",
     "iopub.status.idle": "2026-02-13T18:52:59.308097Z",
     "shell.execute_reply": "2026-02-13T18:52:59.307326Z",
     "shell.execute_reply.started": "2026-02-13T18:52:59.158534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0.1,\n",
    "    r=8,\n",
    "    bias = 'none',\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "print(f\"Before adapter paramters: {model.num_parameters()}\")\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T18:55:52.494833Z",
     "iopub.status.busy": "2026-02-13T18:55:52.494496Z",
     "iopub.status.idle": "2026-02-13T18:55:52.538762Z",
     "shell.execute_reply": "2026-02-13T18:55:52.538219Z",
     "shell.execute_reply.started": "2026-02-13T18:55:52.494807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = SFTConfig(\n",
    "    output_dir=\"./output\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_checkpointing=GRADIENT_CHECKPOINTING,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    eval_steps=EVAL_STEPS,\n",
    "    eval_strategy=EVAL_STRATEGY,\n",
    "    save_strategy=SAVE_STRATEGY,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    metric_for_best_model=METRIC_FOR_BEST_MODEL,\n",
    "    load_best_model_at_end=LOAD_BEST_MODEL_AT_END,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    dataset_kwargs=DATASET_KWARGS,\n",
    "    max_length=MAX_SEQ_LEN,\n",
    "    remove_unused_columns = REMOVE_UNUSED_COLUMNS,\n",
    "    optim=OPTIM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "collate_sample = [train_dataset_formated[0]]\n",
    "\n",
    "def collate_fn(examples):\n",
    "    texts = [processor.apply_chat_template(example[\"messages\"], tokenize=False) for example in examples]\n",
    "    image_inputs = [[views['image'] for views in example[\"messages\"][1][\"content\"][:6]] for example in examples]\n",
    "    batch = processor(\n",
    "        text=texts, images=image_inputs, return_tensors = \"pt\", padding = True,\n",
    "    )\n",
    "\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
    "    batch[\"labels\"] = batch[\"input_ids\"]\n",
    "\n",
    "    return batch\n",
    "\n",
    "collated_data = collate_fn(collate_sample)\n",
    "print(collated_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:43:28.142034Z",
     "iopub.status.busy": "2026-02-13T19:43:28.141387Z",
     "iopub.status.idle": "2026-02-13T19:43:28.294802Z",
     "shell.execute_reply": "2026-02-13T19:43:28.293813Z",
     "shell.execute_reply.started": "2026-02-13T19:43:28.142003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=[data[\"messages\"] for data in train_dataset_formated],\n",
    "    eval_dataset=[data[\"messages\"] for data in eval_dataset_formated],\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=processor.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Initial Evaluation\")\n",
    "metric = trainer.evaluate()\n",
    "print(metric)\n",
    "\n",
    "print(\"Training\")\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
